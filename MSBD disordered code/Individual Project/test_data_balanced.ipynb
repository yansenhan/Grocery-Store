{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\hanya\\Desktop\\MSBD5001 Group Project\\Individual Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('./train.csv').drop('id', axis=1)\n",
    "test_data = pd.read_csv('./test.csv').drop('id',axis=1)\n",
    "training_data['n_jobs'].loc[training_data['n_jobs']==-1] = 16\n",
    "test_data['n_jobs'].loc[test_data['n_jobs']==-1] = 16\n",
    "training_label = training_data['time']\n",
    "data_corr = training_data.corr()['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据平衡\n",
    "training_data2 = pd.DataFrame(columns=training_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    training_data2 = pd.concat([training_data2,\n",
    "        training_data.loc[np.random.choice(training_label[(training_label<i+1) & (training_label>i)].index, size=30), :]])\n",
    "training_data2 = pd.concat([training_data2,training_data.loc[np.random.choice(training_label[training_label>10].index, size=400), :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = training_data2.corr()['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data2.index = range(len(training_data2))\n",
    "training_data = training_data2\n",
    "training_label = training_data2['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop = data_corr[abs(data_corr)<0.1]\n",
    "all_data = pd.concat([training_data.drop('time',axis=1), test_data])#.drop('id',axis=1)])\n",
    "all_data.drop(col_drop.index,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征构造\n",
    "all_data['n_samples_n_jobs'] = all_data['n_samples']/all_data['n_jobs']\n",
    "all_data['max_iter_n_jobs'] = all_data['max_iter']/all_data['n_jobs']\n",
    "all_data['max_iter_n_samples'] = all_data['max_iter']*all_data['n_samples']\n",
    "all_data['n_samples_n_features'] = all_data['n_samples']*all_data['n_features']\n",
    "all_data['n_samples_n_features_max_iter'] = all_data['n_samples']*all_data['n_features']*all_data['max_iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data['penalty'], all_data.iloc[:,1:].astype('float')], axis=1)\n",
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data1 = all_data\n",
    "all_data = pd.concat([all_data1['penalty'],(all_data.iloc[:, 1:] - all_data.iloc[:, 1:].mean())/ all_data.iloc[:, 1:].std()], axis = 1)\n",
    "all_data1 = all_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(all_data)\n",
    "training_len = 650 #len(training_df_data)-test_training\n",
    "test_training = len(training_data) - training_len\n",
    "test_len = len(test_data)\n",
    "\n",
    "X_train = new_data.iloc[:training_len, :] # training data--cross validation\n",
    "X_train_test =  new_data.iloc[training_len:training_len+test_training, :] # training data--test\n",
    "y_train = training_label.iloc[:training_len] # training labels--cross validation\n",
    "y_train_test = training_label.iloc[-test_training:] # training label--test\n",
    "X_test = new_data.iloc[-test_len:, :] # test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn(X_train, y_train, X_train_test, y_train_test):\n",
    "    # 200 100\n",
    "    # 读取数据\n",
    "    x_train = X_train\n",
    "    y_train = y_train\n",
    "    x_test = X_train_test\n",
    "    y_test = y_train_test\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, activation='relu', input_dim=18))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    adm = Adam(lr=0.01, decay=1e-6)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=adm)\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              epochs=1000,\n",
    "              batch_size=300)\n",
    "    score = model.evaluate(x_test, y_test, batch_size=60)\n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u, w = model_nn(X_train, y_train, X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(u.predict(X_test)).to_csv('test_nn_balanced1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(u.predict(X_train_test), index=y_train_test.index), y_train_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
